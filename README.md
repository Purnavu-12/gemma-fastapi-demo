# Gemma-fastapi-demo
"Local Gemma2 2B Chat API with Ollama + FastAPI "

## Gemma2 FastAPI Chat Demo ðŸ”¥

A simple local chat API using **Gemma2 2B** via Ollama + FastAPI.

## Why?
Exploring Gemma models and building developer tools .

## Features
- Real-time chat with Gemma2 (instruction-tuned)
- FastAPI backend (Swagger UI at /docs)
- Easy local setup

## Requirements
1. fastapi
2. uvicorn
3. requests
- use this command: `pip install fastapi uvicorn requests`

## Quick Start
1. Install Ollama: https://ollama.com
2. `ollama run gemma2:2b`
3. In another terminal: `ollama serve`
4. `pip install -r requirements.txt`
5. `python app.py`
6. Open http://127.0.0.1:8000/docs

Excited about Gemma ecosystem! ðŸš€


<img width="517" height="539" alt="Screenshot 2026-01-07 162628" src="https://github.com/user-attachments/assets/b50e02cd-496d-416e-abb3-b2830cdb83d1" />
